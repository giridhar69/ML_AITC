{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the code for 8 queen Dynamic programming problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# board state memory\n",
    "board_state_memory:dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "\n",
    "# creating an N * N board\n",
    "board = np.zeros((N, N), np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create board string\n",
    "def create_board_string(board):\n",
    "    board_string = ''\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            board_string += str(board[i][j])\n",
    "    return board_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000000000000000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the Create_board_string function\n",
    "create_board_string(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying the board and positioning the queen at 1 column, 1 row\n",
    "board_copy = board.copy()\n",
    "board_copy[0, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0100000000000000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_copy\n",
    "create_board_string(board_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_board_safe(board):\n",
    "    \n",
    "    #This is where the dynaic programming comes into picture. Where we use the board_state_memory to cache.\n",
    "    board_key = create_board_string(board)\n",
    "    \n",
    "    if board_key in board_state_memory:\n",
    "        print('Using Cached Information')\n",
    "        return board_state_memory[board_key]\n",
    "    \n",
    "    # calculate the sum in every row of the board\n",
    "    row_sum = np.sum(board, axis = 1)\n",
    "    # checking if a row has more than 1 queen - we will check the sum or elements in a row\n",
    "    if len(row_sum[np.where(row_sum > 1)]) > 0:\n",
    "        board_state_memory[board_key] = False\n",
    "        return False\n",
    "    \n",
    "    # checking column sum in every row of the board\n",
    "    col_sum = np.sum(board, axis = 0)\n",
    "    if len(col_sum[np.where(col_sum > 1)]) > 0:\n",
    "        board_state_memory[board_key] = False\n",
    "        return False\n",
    "    \n",
    "    diags = [board[::-1,:].diagonal(i) for i in range(-board.shape[0] + 1, board.shape[1])]\n",
    "    \n",
    "    diags.extend(board.diagonal(i) for i in range(board.shape[1] - 1, -board.shape[0], -1))\n",
    "    \n",
    "    for diag in diags:\n",
    "        if np.sum(diag) > 1:\n",
    "            board_state_memory[board_key] = False\n",
    "            return False\n",
    "        \n",
    "    board_state_memory[board_key] = True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_copy = board.copy()\n",
    "board_copy[1][0] = 1\n",
    "board_copy[2][3] = 1\n",
    "board_copy[0][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(board_copy)\n",
    "is_board_safe(board_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the placing of the Queen \n",
    "\n",
    "def place_queen_safely(board, column):\n",
    "    \n",
    "    if column >= N:\n",
    "        # All N queens are placed correctly\n",
    "        return True\n",
    "    \n",
    "    for row in range(N):\n",
    "        board[row][column] = 1\n",
    "        \n",
    "        safe = False\n",
    "        \n",
    "        if is_board_safe(board):\n",
    "            safe = place_queen_safely(board, column + 1)\n",
    "    \n",
    "        if not safe:\n",
    "            board[row][column] = 0\n",
    "            \n",
    "        else: \n",
    "            break\n",
    "    return safe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0100000010000000000100000000000000000000000000000000000000000000': False}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_state_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "board = np.zeros((N,N), np.int8)\n",
    "placed = place_queen_safely(board, 0)\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placed\n",
    "# just checking if everything is set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q-learning and SARSA in Reinforcement Learning.\n",
    "Q-learning gives us the optimal policy to maximize the returns in a Reinforcement learning.\n",
    "\n",
    "Agent observes the environment and takes actions based on a policy.\n",
    "The output of reinforcement learning is a set of actions which maximize the cumulative rewards.\n",
    "\n",
    "Policy Search algorithms\n",
    "1. Brute Force methods\n",
    "2. Policy Gradient methods\n",
    "3. Value Function metods\n",
    "\n",
    "Value Function methods are most common\n",
    "\n",
    "Q-learning techniques (Temporal difference)\n",
    "SARSA method (Another implementation of Q-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
